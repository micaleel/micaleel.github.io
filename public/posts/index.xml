<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on micaleel&#39;s notes</title>
    <link>https://micaleel.github.io/posts/</link>
    <description>Recent content in Posts on micaleel&#39;s notes</description>
    <generator>Hugo -- 0.127.0</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Apr 2025 20:07:36 +0100</lastBuildDate>
    <atom:link href="https://micaleel.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Monitoring Recommenders</title>
      <link>https://micaleel.github.io/posts/monitoring-recsys/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://micaleel.github.io/posts/monitoring-recsys/</guid>
      <description>Monitoring and observability systems track the performance and reliability of recommender systems in production. They report metrics computed from model inputs, outputs, and customer interactions. These metrics help organisations assess the health and effectiveness of their recommender systems.
Failure to adopt a proper monitoring and observability system could negatively impact business operations affecting things like user experience and revenue.
I believe there are three main components essential for monitoring a recommender system in production: Metrics, Logging, and Reporting.</description>
      <content:encoded><![CDATA[<p>Monitoring and observability systems track the performance and reliability of recommender systems in production. They report metrics computed from  model inputs, outputs, and customer interactions. These metrics help organisations assess the health and effectiveness of their recommender systems.</p>
<p>Failure to adopt a proper monitoring and observability system could negatively impact business operations affecting things like user experience and revenue.</p>
<p>I believe there are three main components essential for monitoring a recommender system in production: Metrics, Logging, and Reporting.</p>
<h3 id="metrics-measuring-performance-and-business-alignment">Metrics: Measuring Performance and Business Alignment</h3>
<p>Metrics are the backbone of any ML monitoring system because they provide quantifiable insights into model performance and business impact.</p>
<p>For recommender systems, a good starting point is to consider metrics that are commonly used to evaluate retrieval and ranking systems. For example:</p>
<ul>
<li><strong>Accuracy metrics</strong>: NDCG (Normalised Discounted Cumulative Gain), MAP (Mean Average Precision), or MRR (Mean Reciprocal Rank) to evaluate ranking quality.</li>
<li><strong>Engagement metrics</strong>: Click-through rate (CTR), conversion rate, or time spent on recommended items.</li>
<li><strong>Diversity metrics</strong>: Category coverage or variance in item similarity scores (to ensure a varied recommendation set).</li>
<li><strong>Business KPIs</strong>: Revenue or cost per session, or estimated quality of items that delighted the user.</li>
</ul>
<p>Tracking trends and anomalies in metrics could help flag performance degradation or misalignment with business goals.</p>
<h3 id="logging-capturing-inference-data-for-analysis">Logging: Capturing Inference Data for Analysis</h3>
<p>Comprehensive logging is crucial for post-hoc analysis, drift detection, and debugging.</p>
<p>For recommender systems, consider logging:</p>
<ul>
<li><strong>Input features</strong>: User demographics, historical interactions, and contextual information.</li>
<li><strong>Model outputs</strong>: Raw scores, rankings, and final recommendations.</li>
<li><strong>Serving metadata</strong>: Timestamp, model version, and model-serving API version.</li>
<li><strong>User interactions</strong>: Clicks, consumptions, or other engagement signals.</li>
</ul>
<p>This data facilitates the reconstruction the model&rsquo;s decision-making process, detect data drift, and identify patterns in errors or unexpected behaviours.</p>
<h3 id="reporting-visualising-trends-and-anomalies">Reporting: Visualising Trends and Anomalies</h3>
<p>Effective reporting transforms raw data into actionable insights. For recommender systems, consider these reporting strategies:</p>
<ul>
<li><strong>Global performance dashboards</strong>: Visualise key metrics over time, highlighting trends and anomalies.</li>
<li><strong>Segment-level analysis</strong>: Break down performance by user segments, item categories, or geographical regions.</li>
<li><strong>User-level reports</strong>: Enable deep dives into individual user experiences for troubleshooting or personalisation refinement.</li>
<li><strong>Drift monitoring</strong>: Visualise changes in feature distributions or model predictions over time.</li>
<li><strong>A/B test results</strong>: Compare metrics across different model versions or recommendation strategies.</li>
</ul>
<p>These reports should be designed to trigger appropriate actions, whether it&rsquo;s retraining the model, adjusting business rules, or investigating specific issues.</p>
<h3 id="conclusion">Conclusion</h3>
<p>By implementing a robust ML monitoring and observability system, organisations can ensure their recommender systems remain reliable and aligned with business objectives. This approach enables proactive maintenance, faster troubleshooting, and data-driven decision-making, ultimately leading to improved user satisfaction and business outcomes.</p>
<p>The key to success lies in choosing the right metrics, logging comprehensive data, and creating insightful reports that drive action.</p>
]]></content:encoded>
    </item>
    <item>
      <title>AI Washing</title>
      <link>https://micaleel.github.io/posts/ai-washing/</link>
      <pubDate>Sun, 30 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://micaleel.github.io/posts/ai-washing/</guid>
      <description>The promise of generative AI is exaggerated in the short-term and underestimated in the long-term leading to an uncontrollable hype.
Naturally, many choose to ride this hype with false advertisement to further their agenda — whether it is to drive up stock prices or to win customers.
BBC recently referred this false misrepresentation of the benefits of AI (to businesses) as &amp;ldquo;AI washing&amp;rdquo;:
It is a problem that has quietly existed for a number of years, according to data from another tech investment firm, MMC Ventures.</description>
      <content:encoded><![CDATA[<p>The promise of generative AI is exaggerated in the short-term and underestimated in the long-term leading to an uncontrollable hype.</p>
<p>Naturally, many choose to ride this hype with false advertisement to further their agenda — whether it is to drive up stock prices or to win customers.</p>
<p><a href="https://www.bbc.com/news/articles/c9xx8122893o">BBC</a> recently referred this false misrepresentation of the benefits of AI (to businesses) as &ldquo;AI washing&rdquo;:</p>
<blockquote>
<p>It is a problem that has quietly existed for a number of years, according to data from another tech investment firm, MMC Ventures. In a 2019 study it found that 40% of new tech firms that described themselves as &ldquo;AI start-ups&rdquo; in fact used virtually no AI at all.</p>
</blockquote>
<p>Amazon itself decieved customers into thinking that their &ldquo;Just Walk Out&rdquo; technology — that powered Amazon Fresh and Amazon Go shops — was primarly driven by AI. It turned out that <a href="https://www.theverge.com/2024/4/17/24133029/amazon-just-walk-out-cashierless-ai-india">the system was supported by hundreds of works manually checking over 70% of the transactions</a>.</p>
<p>While should eventually expect regulation to tame the false promises of AI to customer, in the short term we must adapt to ridiculous ads like <a href="https://www.bbc.com/news/articles/c9xx8122893o">an AI driven toothbrush</a>.</p>
<p>People charged with developing AI solutions have the impossible task to taming expectations and disabusing the believe the stakeholder have about AI being a silverbullet.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
