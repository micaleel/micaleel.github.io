[{"content":" Monitoring and observability systems track the performance and reliability of recommender systems in production. They report metrics computed from model inputs, outputs, and customer interactions. These metrics help organisations assess the health and effectiveness of their recommender systems.\nFailure to adopt a proper monitoring and observability system could negatively impact business operations affecting things like user experience and revenue.\nI believe there are three main components essential for monitoring a recommender system in production: Metrics, Logging, and Reporting.\nMetrics: Measuring Performance and Business Alignment Metrics are the backbone of any ML monitoring system because they provide quantifiable insights into model performance and business impact.\nFor recommender systems, a good starting point is to consider metrics that are commonly used to evaluate retrieval and ranking systems. For example:\nAccuracy metrics: NDCG (Normalised Discounted Cumulative Gain), MAP (Mean Average Precision), or MRR (Mean Reciprocal Rank) to evaluate ranking quality. Engagement metrics: Click-through rate (CTR), conversion rate, or time spent on recommended items. Diversity metrics: Category coverage or variance in item similarity scores (to ensure a varied recommendation set). Business KPIs: Revenue or cost per session, or estimated quality of items that delighted the user. Tracking trends and anomalies in metrics could help flag performance degradation or misalignment with business goals.\nLogging: Capturing Inference Data for Analysis Comprehensive logging is crucial for post-hoc analysis, drift detection, and debugging.\nFor recommender systems, consider logging:\nInput features: User demographics, historical interactions, and contextual information. Model outputs: Raw scores, rankings, and final recommendations. Serving metadata: Timestamp, model version, and model-serving API version. User interactions: Clicks, consumptions, or other engagement signals. This data facilitates the reconstruction the model\u0026rsquo;s decision-making process, detect data drift, and identify patterns in errors or unexpected behaviours.\nReporting: Visualising Trends and Anomalies Effective reporting transforms raw data into actionable insights. For recommender systems, consider these reporting strategies:\nGlobal performance dashboards: Visualise key metrics over time, highlighting trends and anomalies. Segment-level analysis: Break down performance by user segments, item categories, or geographical regions. User-level reports: Enable deep dives into individual user experiences for troubleshooting or personalisation refinement. Drift monitoring: Visualise changes in feature distributions or model predictions over time. A/B test results: Compare metrics across different model versions or recommendation strategies. These reports should be designed to trigger appropriate actions, whether it\u0026rsquo;s retraining the model, adjusting business rules, or investigating specific issues.\nConclusion By implementing a robust ML monitoring and observability system, organisations can ensure their recommender systems remain reliable and aligned with business objectives. This approach enables proactive maintenance, faster troubleshooting, and data-driven decision-making, ultimately leading to improved user satisfaction and business outcomes.\nThe key to success lies in choosing the right metrics, logging comprehensive data, and creating insightful reports that drive action.\n","permalink":"http://localhost:1313/posts/monitoring-recsys/","summary":"Monitoring and observability systems track the performance and reliability of recommender systems in production. They report metrics computed from model inputs, outputs, and customer interactions. These metrics help organisations assess the health and effectiveness of their recommender systems.\nFailure to adopt a proper monitoring and observability system could negatively impact business operations affecting things like user experience and revenue.\nI believe there are three main components essential for monitoring a recommender system in production: Metrics, Logging, and Reporting.","title":"Monitoring Recommenders"},{"content":"The promise of generative AI is exaggerated in the short-term and underestimated in the long-term leading to an uncontrollable hype.\nNaturally, many choose to ride this hype with false advertisement to further their agenda — whether it is to drive up stock prices or to win customers.\nBBC recently referred this false misrepresentation of the benefits of AI (to businesses) as \u0026ldquo;AI washing\u0026rdquo;:\nIt is a problem that has quietly existed for a number of years, according to data from another tech investment firm, MMC Ventures. In a 2019 study it found that 40% of new tech firms that described themselves as \u0026ldquo;AI start-ups\u0026rdquo; in fact used virtually no AI at all.\nAmazon itself decieved customers into thinking that their \u0026ldquo;Just Walk Out\u0026rdquo; technology — that powered Amazon Fresh and Amazon Go shops — was primarly driven by AI. It turned out that the system was supported by hundreds of works manually checking over 70% of the transactions.\nWhile should eventually expect regulation to tame the false promises of AI to customer, in the short term we must adapt to ridiculous ads like an AI driven toothbrush.\nPeople charged with developing AI solutions have the impossible task to taming expectations and disabusing the believe the stakeholder have about AI being a silverbullet.\n","permalink":"http://localhost:1313/posts/ai-washing/","summary":"The promise of generative AI is exaggerated in the short-term and underestimated in the long-term leading to an uncontrollable hype.\nNaturally, many choose to ride this hype with false advertisement to further their agenda — whether it is to drive up stock prices or to win customers.\nBBC recently referred this false misrepresentation of the benefits of AI (to businesses) as \u0026ldquo;AI washing\u0026rdquo;:\nIt is a problem that has quietly existed for a number of years, according to data from another tech investment firm, MMC Ventures.","title":"AI Washing"},{"content":" Structural subtyping in Python can be achieved using typing.Protocol and the @runtime_checkable decorator.\nRather than employing abc.ABC for nominal subclasses, a cleaner approach involves combining @typing.runtime_checkable with typing.Protocol.\nBy decorating a protocol class with @runtime_checkable, it becomes a runtime protocol which is amenable to isinstance() and issubclass(). Without @runtime_checkable, attempting isinstance() and issubclass() operations will result in a TypeError. Note that, for performance considerations, using hasattr() tends to be notably faster than isinstance() in these cases.\nStructural subtyping is common to languages like Golang and C#, and it sidesteps issues associated with inheritance by favoring compositions.\nFor a comprehensive understanding and further details, refer to the Python Enhancement Proposal (PEP) 544 available at https://peps.python.org/pep-0544/.\nThis article is inspired by Hynek Schlawack\u0026rsquo;s talk: Subclassing, Composition, Python, and You.\n","permalink":"http://localhost:1313/posts/structural-subtyping/","summary":"Structural subtyping in Python can be achieved using typing.Protocol and the @runtime_checkable decorator.\nRather than employing abc.ABC for nominal subclasses, a cleaner approach involves combining @typing.runtime_checkable with typing.Protocol.\nBy decorating a protocol class with @runtime_checkable, it becomes a runtime protocol which is amenable to isinstance() and issubclass(). Without @runtime_checkable, attempting isinstance() and issubclass() operations will result in a TypeError. Note that, for performance considerations, using hasattr() tends to be notably faster than isinstance() in these cases.","title":"Structural Subtyping in Python"},{"content":"I am a programmer turned AI practitioner\n","permalink":"http://localhost:1313/about/","summary":"I am a programmer turned AI practitioner","title":""},{"content":" Naked Money: A Revealing Look at Our Financial System ","permalink":"http://localhost:1313/bookshelf/","summary":" Naked Money: A Revealing Look at Our Financial System ","title":"Bookshelf"}]